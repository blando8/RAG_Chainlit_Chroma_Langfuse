user_input,reference_contexts,reference,synthesizer_name
What role does the Intelligent Informatics and Service Innovation Research Center play in the development of Thai-centric large language models?,"['OPEN THAI GPT 1.6 AND R1: T HAI -CENTRIC OPEN -SOURCE\nAND REASONING LARGE LANGUAGE MODELS\nTECHNICAL REPORT\nSumeth Yuenyong*1, Thodsaporn Chay-intr†2,3 , and Kobkrit Viriyayudhakorn‡2,3,4\n1Department of Computer Science, Faculty of Engineering, Mahidol University, Thailand\n2iApp Technology Co., Ltd., Thailand\n3Intelligent Informatics and Service Innovation Research Center, Thailand\n4Artificial Intelligence Entrepreneur Association of Thailand (AIEAT), Thailand\nABSTRACT\nWe present OpenThaiGPT 1.6 and R1 (OTG-1.6 and OTG-R1), Thai-centric Large Language Models\n(LLMs) developed through distinct methodologies to enhance generalization and reasoning capabil-\nities. OTG-1.6 employs Task Arithmetic model merging for broad generalization, while OTG-R1\nintegrates multi-stage training with the Less-Is-More Reasoning Hypothesis (LIMO) for advanced\nreasoning. Benchmark evaluations demonstrate superior performance across Thai language tasks,']","The Intelligent Informatics and Service Innovation Research Center is involved in the development of Thai-centric large language models, as indicated by its association with the authors of the technical report on OpenThaiGPT 1.6 and R1, which are Thai-centric large language models developed to enhance generalization and reasoning capabilities.",single_hop_specifc_query_synthesizer
How have recent advancements in LLMs improved their performance in natural language tasks?,"['integrates multi-stage training with the Less-Is-More Reasoning Hypothesis (LIMO) for advanced\nreasoning. Benchmark evaluations demonstrate superior performance across Thai language tasks,\nachieving competitive results against larger-scale open-source Thai LLMs. This paper details the pro-\nposed models, training processes, benchmarks, and results, highlighting improvements over previous\nmodels and establishing new performance standards for Thai-centric LLMs.\n1 Introduction\nThe development of Large Language Models (LLMs) has significantly advanced natural language understanding,\nreasoning, and generation capabilities [OpenAI, 2024, Gemma, 2025, DeepSeek-AI, 2025, Xu et al., 2025]. Recent\nmodels have demonstrated impressive performance across various tasks by leveraging sophisticated architectures,\nextensive training data, and improved training methodologies [Qin et al., 2024, Luo et al., 2025, OpenAI, 2025].']","Recent advancements in Large Language Models (LLMs) have significantly enhanced their natural language understanding, reasoning, and generation capabilities. These improvements are attributed to sophisticated architectures, extensive training data, and improved training methodologies, leading to impressive performance across various tasks.",single_hop_specifc_query_synthesizer
What contribution did Goddard et al. make to the development of OpenThaiGPT 1.6?,"['extensive training data, and improved training methodologies [Qin et al., 2024, Luo et al., 2025, OpenAI, 2025].\nHowever, achieving optimal performance for Thai-centric LLMs remains challenging due to linguistic complexities,\nlimited high-quality datasets, and inadequate adaptation of general LLM architectures to Thai-specific tasks.\nAddressing these challenges requires techniques that enhance generalization, reasoning, and efficiency without ex-\ncessively increasing model scale. We present OpenThaiGPT 1.6 (OTG-1.6) and OpenThaiGPT R1 (OTG-R1),\ndeveloped using complementary methodologies to overcome these limitations. OTG-1.6 applies Task Arithmetic model\nmerging to combine specialized models, improving generalization across diverse tasks without increasing computational\nrequirements [Ilharco et al., 2023, Goddard et al., 2024]. Meanwhile, OTG-R1, inspired by DeepSeek-R1 [DeepSeek-']","Goddard et al. contributed to the development of OpenThaiGPT 1.6 by applying Task Arithmetic model merging to combine specialized models, which improves generalization across diverse tasks without increasing computational requirements.",single_hop_specifc_query_synthesizer
Wht is DeepSeek-R1?,"['requirements [Ilharco et al., 2023, Goddard et al., 2024]. Meanwhile, OTG-R1, inspired by DeepSeek-R1 [DeepSeek-\nAI, 2025], employs multi-stage training and the Less-Is-More Reasoning Hypothesis (LIMO) to enhance reasoning\ncapabilities with limited data [Ye et al., 2025].\nBenchmark evaluations demonstrate that OTG-1.6 and OTG-R1 achieve superior performance across various Thai\nlanguage tasks, with OTG-1.6 excelling in generalization tasks and OTG-R1 achieving competitive or superior results\non reasoning benchmarks despite its smaller model size.\n∗sumeth.yue@mahidol.edu, ORCID: 0000-0001-7774-0291\n†t.chayintr@gmail.com, ORCID: 0000-0002-7287-7579\n‡kobkrit@aieat.or.th, ORCID: 0000-0001-6700-7248\narXiv:2504.01789v1  [cs.CL]  2 Apr 2025']","DeepSeek-R1 is a model that inspired OTG-R1, which employs multi-stage training and the Less-Is-More Reasoning Hypothesis (LIMO) to enhance reasoning capabilities with limited data.",single_hop_specifc_query_synthesizer
What are the specific hyperparameters used for training the OTG-R1 model?,"['8x H100 GPUs. The detailed hyperparameters are provided in Table 1.\nParameter OTG-1.6 (72B) OTG-R1 (32B)\nBase Model Qwen2.5-72B-Instruct DeepSeek-R1-Distill-Qwen-32B\nLearning Rate 1 × 10−4\nLoRA Rank 64\nLoRA Alpha 128\nEpochs 3\nGPUs 8x H100\nTraining Framework MS Swift + DeepSpeed\nBatch Size per Device 4 2\nGradient Accumulation 1 2\nMaximum Length (Initial Training) 2400 tokens 8192 tokens\nMaximum Length (Extended Training) N/A 16384 tokens\nTable 1: Training Hyperparameters for OTG-1.6 (72B) and OTG-R1 (32B). Common hyperparameters are displayed in\nunified rows.\n2.1 OTG-1.6: General Model (72B)\nOTG-1.6 was developed to achieve broad generalization across various domains. The model training involved\nmultiple datasets covering general instructions, translation pairs, and standardized Thai examinations. The gen-\neral instruction dataset was derived from Thaweewat/alpaca-cleaned-52k-th6, OpenAssistant/oasst17, and']","The OTG-R1 model uses the following hyperparameters: Base Model - DeepSeek-R1-Distill-Qwen-32B, Learning Rate - 1 × 10−4, LoRA Rank - 64, LoRA Alpha - 128, Epochs - 3, GPUs - 8x H100, Training Framework - MS Swift + DeepSpeed, Batch Size per Device - 2, Gradient Accumulation - 2, Maximum Length (Initial Training) - 8192 tokens, Maximum Length (Extended Training) - 16384 tokens.",single_hop_specifc_query_synthesizer
What ONET do?,"['eral instruction dataset was derived from Thaweewat/alpaca-cleaned-52k-th6, OpenAssistant/oasst17, and\nThaweewat/gpteacher-20k-th8. Bilingual datasets from Lexitron (English and Thai) were included to enhance\ncross-lingual understanding. Additionally, standardized examination datasets, including ONET and TGAT, were\nincorporated to improve domain-specific performance.\nModel Merging: The models trained on these datasets were subsequently merged using mergekit [Goddard et al.,\n2024] through Task Arithmetic model merging. This process involved weighted merging of specialized models to\nenhance generalization without increasing computational requirements. The merging weights were assigned as follows:\nGeneral Instructions Model (0.15), Translation Pairs Model (0.15), and Thai Exams Model (0.70). Model merging\nfacilitated the integration of specialized knowledge from distinct datasets, enhancing the model’s robustness and\nperformance across diverse tasks.\n2.2 OTG-R1: Reasoning Model (32B)']",ONET datasets were incorporated to improve domain-specific performance.,single_hop_specifc_query_synthesizer
How does the Qwen/Qwen2.5-72B-Instruct model enhance performance across diverse tasks?,"['facilitated the integration of specialized knowledge from distinct datasets, enhancing the model’s robustness and\nperformance across diverse tasks.\n2.2 OTG-R1: Reasoning Model (32B)\nOTG-R1 was developed to enhance reasoning capabilities, particularly for structured and complex tasks. The model was\ninitially trained using various instruction-based datasets, including Thaweewat/alpaca-cleaned-52k-th9,\n4https://huggingface.co/Qwen/Qwen2.5-72B-Instruct\n5https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n6https://huggingface.co/datasets/Thaweewat/alpaca-cleaned-52k-th\n7https://huggingface.co/datasets/OpenAssistant/oasst1\n8https://huggingface.co/datasets/Thaweewat/gpteacher-20k-th\n9https://huggingface.co/datasets/Thaweewat/alpaca-cleaned-52k-th\n2']","The Qwen/Qwen2.5-72B-Instruct model enhances performance across diverse tasks by facilitating the integration of specialized knowledge from distinct datasets, thereby improving the model's robustness and performance.",single_hop_specifc_query_synthesizer
What Thaweewat/gpteacher-20k-th11 do in OpenThaiGPT 1.6 training?,"['OpenThaiGPT 1.6 and R1 TECHNICAL REPORT\nOpenAssistant/oasst110, Thaweewat/gpteacher-20k-th11, iapp/Thai-R1-Distill-SFT12, and\nServiceNow-AI/R1-Distill-SFT13. Additionally, standardized examination datasets, including ONET and\nTGAT, were incorporated to improve foundational reasoning capabilities through comprehensive dataset coverage.\nMulti-Stage Training: OTG-R1 employed a progressive training process involving multiple rounds to refine reasoning\ncapabilities. The initial training phase utilized a maximum sequence length of 8192 tokens, which was extended to\n16384 tokens in the subsequent phase. This progression allowed the model to process increasingly complex queries\nwhile maintaining computational efficiency.\nLIMO Integration: To enhance reasoning performance with limited high-quality data, the LIMO dataset 14 was\nincorporated during the second training phase. This dataset was applied without translation to preserve contextual']","Thaweewat/gpteacher-20k-th11 is one of the models used in the OpenThaiGPT 1.6 training process, which involved a progressive training process with multiple rounds to refine reasoning capabilities.",single_hop_specifc_query_synthesizer
What is the AIME24-TH benchmark used for in model evaluations?,"['incorporated during the second training phase. This dataset was applied without translation to preserve contextual\nintegrity. The integration of LIMO aimed to leverage high-quality, contextually relevant data to improve reasoning\nefficiency and accuracy.\n3 Experiments\nThe trained models were evaluated on multiple benchmarks that cover a diverse range of tasks, including mathematical\nreasoning, language comprehension, coding skills, and general knowledge. The evaluation aimed to assess the models’\ngeneralization, reasoning capabilities, and consistency across tasks.\n3.1 Benchmarks\nThe evaluation used various benchmarks designed to test the specific abilities of the models. Each benchmark is\ndescribed in the following:\n• AIME24-TH: A Thai translation of the American Invitational Mathematics Examination (AIME) dataset\nfocusing on advanced mathematical reasoning and problem solving.\n• MATH500-TH: A Thai-specific mathematical reasoning dataset curated to evaluate calculation skills, logic,']","The AIME24-TH benchmark is a Thai translation of the American Invitational Mathematics Examination (AIME) dataset, focusing on advanced mathematical reasoning and problem solving.",single_hop_specifc_query_synthesizer
what otg-1.6 do in thai language models and how it compare to other models?,"['focusing on advanced mathematical reasoning and problem solving.\n• MATH500-TH: A Thai-specific mathematical reasoning dataset curated to evaluate calculation skills, logic,\nand conceptual understanding.\n• LiveCodeBench-TH: A coding benchmark adapted for Thai that evaluates the models’ ability to understand,\ngenerate, and debug code snippets based on Thai-language prompts.\n• OpenThaiEval: A comprehensive evaluation suite designed for Thai language models that assessesses general\nknowledge, comprehension, and contextual reasoning.\n• Language Accuracy: A benchmark aimed at evaluating the models’ consistency and accuracy in generating\nresponses in Thai, particularly focusing on grammatical correctness and coherence.\n3.2 Results\nThe performance of OTG-1.6 and OTG-R1 was evaluated against several existing models. The results are summarized\nin Tables 2 and 3.\n3.2.1 General Model\nOTG-1.6 was compared to previous OpenThaiGPT versions and other Thai LLMs, including Typhoon2 and']","OTG-1.6 was evaluated against several existing models, including previous OpenThaiGPT versions and other Thai LLMs like Typhoon2. It focuses on advanced mathematical reasoning and problem solving, and its performance is summarized in Tables 2 and 3.",single_hop_specifc_query_synthesizer
